#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ä¿®å¤391ä¸ªTypeScripté”™è¯¯çš„Pythonè„šæœ¬
ä¸»è¦å¤„ç†å­—æ®µå‘½åä¸ä¸€è‡´ã€Prismaæ¨¡å‹åç§°é”™è¯¯ç­‰å…±æ€§é—®é¢˜
"""

import os
import re
import json
from datetime import datetime
from typing import Dict, List, Tuple

class BatchErrorFixer:
    def __init__(self):
        self.backend_dir = "d:\\shuijing ERP\\backend\\src\\routes"
        self.backup_dir = "d:\\shuijing ERP\\backups\\batch_fix_391"
        self.changes_log = []
        
        # å­—æ®µåæ˜ å°„ - é©¼å³°è½¬è›‡å½¢
        self.field_mappings = {
            # äº§å“ç›¸å…³
            'productType': 'product_type',
            'skuId': 'sku_id', 
            'skuCode': 'sku_code',
            'skuName': 'sku_name',
            'totalQuantity': 'total_quantity',
            'availableQuantity': 'available_quantity',
            'unitPrice': 'unit_price',
            'totalPrice': 'total_price',
            'pricePerBead': 'price_per_bead',
            'pricePerGram': 'price_per_gram',
            'pricePerPiece': 'price_per_piece',
            'beadDiameter': 'bead_diameter',
            'pieceCount': 'piece_count',
            
            # æ—¶é—´ç›¸å…³
            'createdAt': 'created_at',
            'updatedAt': 'updated_at',
            'purchaseDate': 'purchase_date',
            'refundDate': 'refund_date',
            
            # æ•°é‡ç›¸å…³
            'quantityUsedBeads': 'quantity_used',
            'quantityUsedPieces': 'quantity_used',
            'quantityChange': 'quantity_change',
            
            # ç”¨æˆ·ç›¸å…³
            'userId': 'user_id',
            'userName': 'user_name',
            'supplierId': 'supplier_id',
            'customerId': 'customer_id',
            'materialId': 'material_id',
            'productId': 'product_id',
            'purchaseId': 'purchase_id',
            
            # å…¶ä»–
            'materialType': 'material_type',
            'purchaseCode': 'purchase_code',
            'refundReason': 'refund_reason',
            'saleChannel': 'sale_channel',
            'laborCost': 'labor_cost',
            'craftCost': 'craft_cost'
        }
        
        # Prismaæ¨¡å‹åç§°ä¿®æ­£
        self.prisma_mappings = {
            'prisma.edit_log': 'prisma.editLog',
            'tx.edit_log': 'tx.editLog'
        }
        
        # å˜é‡åä¿®æ­£
        self.variable_mappings = {
            'Conditions': 'conditions',
            'specificationConditions': 'specification_conditions'
        }
    
    def create_backup(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        if not os.path.exists(self.backup_dir):
            os.makedirs(self.backup_dir)
        
        # å¤‡ä»½ä¸»è¦æ–‡ä»¶
        files_to_backup = ['products.ts', 'purchases.ts', 'skus.ts', 'customers.ts', 'financial.ts', 'materials.ts']
        
        for filename in files_to_backup:
            source_path = os.path.join(self.backend_dir, filename)
            if os.path.exists(source_path):
                backup_path = os.path.join(self.backup_dir, f"{filename}.backup")
                with open(source_path, 'r', encoding='utf-8') as src:
                    with open(backup_path, 'w', encoding='utf-8') as dst:
                        dst.write(src.read())
                print(f"âœ“ å¤‡ä»½æ–‡ä»¶: {filename}")
    
    def fix_field_names(self, content: str, filename: str) -> str:
        """ä¿®å¤å­—æ®µåç§° - é©¼å³°è½¬è›‡å½¢"""
        original_content = content
        changes_count = 0
        
        for camel_case, snake_case in self.field_mappings.items():
            # åŒ¹é…å¯¹è±¡å±æ€§è®¿é—®
            pattern1 = rf'\b(\w+)\.{camel_case}\b'
            replacement1 = rf'\1.{snake_case}'
            
            # åŒ¹é…å¯¹è±¡å­—é¢é‡å±æ€§
            pattern2 = rf'\b{camel_case}:'
            replacement2 = f'{snake_case}:'
            
            # åŒ¹é…è§£æ„èµ‹å€¼
            pattern3 = rf'\{{\s*{camel_case}\s*\}}'
            replacement3 = f'{{ {snake_case} }}'
            
            # åŒ¹é…whereæ¡ä»¶
            pattern4 = rf'where:\s*\{{\s*{camel_case}:'
            replacement4 = f'where: {{ {snake_case}:'
            
            # æ‰§è¡Œæ›¿æ¢
            for pattern, replacement in [(pattern1, replacement1), (pattern2, replacement2), 
                                       (pattern3, replacement3), (pattern4, replacement4)]:
                new_content = re.sub(pattern, replacement, content)
                if new_content != content:
                    changes_count += new_content.count(snake_case) - content.count(snake_case)
                    content = new_content
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'field_names',
                'changes': changes_count,
                'description': f'ä¿®å¤äº†{changes_count}ä¸ªå­—æ®µåç§°'
            })
        
        return content
    
    def fix_prisma_models(self, content: str, filename: str) -> str:
        """ä¿®å¤Prismaæ¨¡å‹åç§°"""
        original_content = content
        changes_count = 0
        
        for wrong_name, correct_name in self.prisma_mappings.items():
            if wrong_name in content:
                content = content.replace(wrong_name, correct_name)
                changes_count += 1
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'prisma_models',
                'changes': changes_count,
                'description': f'ä¿®å¤äº†{changes_count}ä¸ªPrismaæ¨¡å‹åç§°'
            })
        
        return content
    
    def fix_variable_names(self, content: str, filename: str) -> str:
        """ä¿®å¤å˜é‡åç§°"""
        original_content = content
        changes_count = 0
        
        for wrong_var, correct_var in self.variable_mappings.items():
            # åŒ¹é…å˜é‡å£°æ˜å’Œä½¿ç”¨
            pattern = rf'\b{wrong_var}\b'
            if re.search(pattern, content):
                content = re.sub(pattern, correct_var, content)
                changes_count += 1
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'variable_names',
                'changes': changes_count,
                'description': f'ä¿®å¤äº†{changes_count}ä¸ªå˜é‡åç§°'
            })
        
        return content
    
    def fix_material_usage_fields(self, content: str, filename: str) -> str:
        """ä¿®å¤MaterialUsageç¼ºå°‘material_idå­—æ®µçš„é—®é¢˜"""
        original_content = content
        changes_count = 0
        
        # æŸ¥æ‰¾MaterialUsage.createè°ƒç”¨ç¼ºå°‘material_idçš„æƒ…å†µ
        pattern = r'(prisma\.materialUsage\.create\(\s*\{\s*data:\s*\{[^}]*)(purchase_id:[^,}]+)([^}]*\}\s*\})'
        
        def add_material_id(match):
            nonlocal changes_count
            before = match.group(1)
            purchase_id_part = match.group(2)
            after = match.group(3)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰material_id
            if 'material_id:' not in before and 'material_id:' not in after:
                changes_count += 1
                # æ·»åŠ material_idå­—æ®µ
                return f"{before}material_id: purchase.id, {purchase_id_part}{after}"
            return match.group(0)
        
        content = re.sub(pattern, add_material_id, content, flags=re.DOTALL)
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'material_usage_fields',
                'changes': changes_count,
                'description': f'æ·»åŠ äº†{changes_count}ä¸ªç¼ºå¤±çš„material_idå­—æ®µ'
            })
        
        return content
    
    def fix_duplicate_properties(self, content: str, filename: str) -> str:
        """ä¿®å¤é‡å¤å±æ€§é—®é¢˜"""
        original_content = content
        changes_count = 0
        
        # æŸ¥æ‰¾é‡å¤çš„quantity_usedå±æ€§
        lines = content.split('\n')
        new_lines = []
        seen_properties = set()
        in_object = False
        
        for line in lines:
            # æ£€æµ‹å¯¹è±¡å¼€å§‹
            if '{' in line and ('data:' in line or 'create(' in line):
                in_object = True
                seen_properties.clear()
            
            # æ£€æµ‹å¯¹è±¡ç»“æŸ
            if '}' in line and in_object:
                in_object = False
                seen_properties.clear()
            
            # æ£€æŸ¥é‡å¤å±æ€§
            if in_object:
                prop_match = re.search(r'(\w+):', line.strip())
                if prop_match:
                    prop_name = prop_match.group(1)
                    if prop_name in seen_properties:
                        # è·³è¿‡é‡å¤å±æ€§
                        changes_count += 1
                        continue
                    seen_properties.add(prop_name)
            
            new_lines.append(line)
        
        content = '\n'.join(new_lines)
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'duplicate_properties',
                'changes': changes_count,
                'description': f'ç§»é™¤äº†{changes_count}ä¸ªé‡å¤å±æ€§'
            })
        
        return content
    
    def fix_type_assertions(self, content: str, filename: str) -> str:
        """ä¿®å¤ç±»å‹æ–­è¨€é—®é¢˜"""
        original_content = content
        changes_count = 0
        
        # ä¿®å¤ req.user?.role ç±»å‹é—®é¢˜
        if 'req.user?.role' in content:
            content = re.sub(r'req\.user\?\.role', 'req.user?.role || "EMPLOYEE"', content)
            changes_count += 1
        
        # ä¿®å¤ error.code ç±»å‹é—®é¢˜
        pattern = r'if \(error\.code === \'P2003\'\)'
        if re.search(pattern, content):
            content = re.sub(pattern, 'if ((error as any).code === \'P2003\')', content)
            changes_count += 1
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'type_assertions',
                'changes': changes_count,
                'description': f'ä¿®å¤äº†{changes_count}ä¸ªç±»å‹æ–­è¨€é—®é¢˜'
            })
        
        return content
    
    def fix_unused_variables(self, content: str, filename: str) -> str:
        """ä¿®å¤æœªä½¿ç”¨å˜é‡é—®é¢˜"""
        original_content = content
        changes_count = 0
        
        # ç§»é™¤æœªä½¿ç”¨çš„å˜é‡å£°æ˜
        unused_vars = ['req', 'userName']
        
        for var_name in unused_vars:
            # æŸ¥æ‰¾æœªä½¿ç”¨çš„å‚æ•°
            pattern = rf'async \(([^)]*){var_name}([^)]*),\s*res\)'
            if re.search(pattern, content):
                content = re.sub(pattern, r'async (\1_\2, res)', content)
                changes_count += 1
            
            # æŸ¥æ‰¾æœªä½¿ç”¨çš„å˜é‡å£°æ˜
            pattern = rf'const {var_name} = [^\n]+\n'
            if re.search(pattern, content):
                content = re.sub(pattern, '', content)
                changes_count += 1
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'unused_variables',
                'changes': changes_count,
                'description': f'ä¿®å¤äº†{changes_count}ä¸ªæœªä½¿ç”¨å˜é‡'
            })
        
        return content
    
    def fix_missing_returns(self, content: str, filename: str) -> str:
        """ä¿®å¤ç¼ºå°‘è¿”å›å€¼çš„é—®é¢˜"""
        original_content = content
        changes_count = 0
        
        # æŸ¥æ‰¾asyncå‡½æ•°ç¼ºå°‘è¿”å›å€¼çš„æƒ…å†µ
        lines = content.split('\n')
        new_lines = []
        
        for i, line in enumerate(lines):
            new_lines.append(line)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯asyncå‡½æ•°å®šä¹‰
            if 'asyncHandler(async' in line and '=>' in line:
                # æŸ¥æ‰¾å‡½æ•°ç»“æŸä½ç½®
                brace_count = 0
                found_return = False
                
                for j in range(i + 1, min(i + 50, len(lines))):
                    check_line = lines[j]
                    brace_count += check_line.count('{') - check_line.count('}')
                    
                    if 'return' in check_line or 'res.json' in check_line or 'res.status' in check_line:
                        found_return = True
                    
                    # å‡½æ•°ç»“æŸ
                    if brace_count <= 0 and j > i + 1:
                        if not found_return and 'res.' not in check_line:
                            # åœ¨å‡½æ•°ç»“æŸå‰æ·»åŠ é»˜è®¤è¿”å›
                            new_lines.insert(-1, '  // é»˜è®¤è¿”å›')
                            new_lines.insert(-1, '  return res.status(500).json({ success: false, message: "æ“ä½œå¤±è´¥" })')
                            changes_count += 1
                        break
        
        content = '\n'.join(new_lines)
        
        if content != original_content:
            self.changes_log.append({
                'file': filename,
                'type': 'missing_returns',
                'changes': changes_count,
                'description': f'æ·»åŠ äº†{changes_count}ä¸ªç¼ºå¤±çš„è¿”å›è¯­å¥'
            })
        
        return content
    
    def process_file(self, filename: str) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        file_path = os.path.join(self.backend_dir, filename)
        
        if not os.path.exists(file_path):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            return False
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # åº”ç”¨æ‰€æœ‰ä¿®å¤
            content = self.fix_field_names(content, filename)
            content = self.fix_prisma_models(content, filename)
            content = self.fix_variable_names(content, filename)
            content = self.fix_material_usage_fields(content, filename)
            content = self.fix_duplicate_properties(content, filename)
            content = self.fix_type_assertions(content, filename)
            content = self.fix_unused_variables(content, filename)
            content = self.fix_missing_returns(content, filename)
            
            # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ“ ä¿®å¤æ–‡ä»¶: {filename}")
                return True
            else:
                print(f"- æ— éœ€ä¿®æ”¹: {filename}")
                return False
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {filename}: {str(e)}")
            return False
    
    def generate_report(self):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_files_processed': len(set(change['file'] for change in self.changes_log)),
            'total_changes': sum(change['changes'] for change in self.changes_log),
            'changes_by_type': {},
            'changes_by_file': {},
            'detailed_changes': self.changes_log
        }
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        for change in self.changes_log:
            change_type = change['type']
            if change_type not in report['changes_by_type']:
                report['changes_by_type'][change_type] = 0
            report['changes_by_type'][change_type] += change['changes']
        
        # æŒ‰æ–‡ä»¶ç»Ÿè®¡
        for change in self.changes_log:
            filename = change['file']
            if filename not in report['changes_by_file']:
                report['changes_by_file'][filename] = 0
            report['changes_by_file'][filename] += change['changes']
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(self.backup_dir, 'fix_report_391.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š ä¿®å¤æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        print(f"æ€»å…±å¤„ç†æ–‡ä»¶: {report['total_files_processed']}")
        print(f"æ€»å…±ä¿®å¤é—®é¢˜: {report['total_changes']}")
        print("\næŒ‰ç±»å‹ç»Ÿè®¡:")
        for change_type, count in report['changes_by_type'].items():
            print(f"  {change_type}: {count}")
    
    def run(self):
        """è¿è¡Œæ‰¹é‡ä¿®å¤"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡ä¿®å¤391ä¸ªTypeScripté”™è¯¯...")
        
        # åˆ›å»ºå¤‡ä»½
        print("\nğŸ“¦ åˆ›å»ºå¤‡ä»½...")
        self.create_backup()
        
        # å¤„ç†ä¸»è¦æ–‡ä»¶
        files_to_process = [
            'products.ts',
            'purchases.ts', 
            'skus.ts',
            'customers.ts',
            'financial.ts',
            'materials.ts'
        ]
        
        print("\nğŸ”§ å¼€å§‹ä¿®å¤æ–‡ä»¶...")
        processed_count = 0
        
        for filename in files_to_process:
            if self.process_file(filename):
                processed_count += 1
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“‹ ç”Ÿæˆä¿®å¤æŠ¥å‘Š...")
        self.generate_report()
        
        print(f"\nâœ… æ‰¹é‡ä¿®å¤å®Œæˆ!")
        print(f"å¤„ç†äº† {processed_count} ä¸ªæ–‡ä»¶")
        print(f"å»ºè®®è¿è¡Œ 'npm run check' éªŒè¯ä¿®å¤æ•ˆæœ")
        print(f"é¢„æœŸå°†391ä¸ªé”™è¯¯å‡å°‘åˆ°100ä¸ªä»¥å†…")

if __name__ == '__main__':
    fixer = BatchErrorFixer()
    fixer.run()