#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡‡è´­å½•å…¥å­—æ®µè›‡å½¢å‘½åè½¬æ¢è„šæœ¬
æ‰¹é‡å°†é‡‡è´­å½•å…¥ç›¸å…³çš„é©¼å³°å‘½åå­—æ®µè½¬æ¢ä¸ºè›‡å½¢å‘½å
"""

import os
import re
import json
import shutil
from datetime import datetime
from pathlib import Path

# å­—æ®µæ˜ å°„å…³ç³»
FIELD_MAPPINGS = {
    # çŠ¶æ€ç®¡ç†å­—æ®µè½¬æ¢ (12ä¸ª)
    'selectedMaterialType': 'selected_material_type',
    'selectedUnitType': 'selected_unit_type', 
    'isCameraActive': 'is_camera_active',
    'cameraError': 'camera_error',
    'forceEnableCamera': 'force_enable_camera',
    'fileDataList': 'file_data_list',
    'aiParsing': 'ai_parsing',
    'loadingSuppliers': 'loading_suppliers',
    'supplierInput': 'supplier_input',
    'showSupplierDropdown': 'show_supplier_dropdown',
    'filteredSuppliers': 'filtered_suppliers',
    'creatingSupplier': 'creating_supplier',
    
    # å‡½æ•°åè½¬æ¢ (7ä¸ª)
    'handleMaterialTypeChange': 'handle_material_type_change',
    'loadSuppliers': 'load_suppliers',
    'handleSupplierInputChange': 'handle_supplier_input_change',
    'handleSupplierSelect': 'handle_supplier_select',
    'handleAiParse': 'handle_ai_parse',
    'calculateMissingValue': 'calculate_missing_value',
    'onSubmit': 'on_submit',
    
    # è®¡ç®—å­—æ®µè½¬æ¢ (4ä¸ª)
    'beadsPerString': 'beads_per_string',
    'totalBeads': 'total_beads',
    'unitPrice': 'unit_price',
    'pricePerBead': 'price_per_bead',
    
    # å…¶ä»–å­—æ®µè½¬æ¢ (6ä¸ª)
    'purchaseCode': 'purchase_code',
    'supplierId': 'supplier_id',
    'createdBy': 'created_by',
    'createdAt': 'created_at',
    'updatedAt': 'updated_at',
    'aiRecognitionResult': 'ai_recognition_result'
}

# æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {'.ts', '.tsx', '.js', '.jsx', '.json'}

# éœ€è¦éå†çš„ç›®å½•
TARGET_DIRECTORIES = ['src', 'backend', 'shared', 'tests']

# å¤‡ä»½ç›®å½•
BACKUP_DIR = 'backup_purchase_fields'

class PurchaseFieldReplacer:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.backup_dir = self.project_root / BACKUP_DIR
        self.stats = {
            'files_processed': 0,
            'files_modified': 0,
            'total_replacements': 0,
            'field_stats': {field: 0 for field in FIELD_MAPPINGS.keys()},
            'start_time': datetime.now()
        }
        
    def create_backup_dir(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        if self.backup_dir.exists():
            shutil.rmtree(self.backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºå¤‡ä»½ç›®å½•: {self.backup_dir}")
        
    def backup_file(self, file_path):
        """å¤‡ä»½æ–‡ä»¶"""
        relative_path = file_path.relative_to(self.project_root)
        backup_path = self.backup_dir / relative_path
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(file_path, backup_path)
        
    def should_process_file(self, file_path):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å¤„ç†è¯¥æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if file_path.suffix not in SUPPORTED_EXTENSIONS:
            return False
            
        # æ’é™¤å¤‡ä»½ç›®å½•
        if BACKUP_DIR in str(file_path):
            return False
            
        # æ’é™¤node_modulesç­‰ç›®å½•
        exclude_dirs = {'node_modules', '.git', 'dist', 'build', 'coverage'}
        if any(part in exclude_dirs for part in file_path.parts):
            return False
            
        return True
        
    def create_replacement_patterns(self):
        """åˆ›å»ºæ›¿æ¢æ¨¡å¼"""
        patterns = []
        
        for old_field, new_field in FIELD_MAPPINGS.items():
            # 1. å˜é‡å£°æ˜å’Œèµ‹å€¼ (const, let, var)
            patterns.append({
                'pattern': rf'\b(const|let|var)\s+{re.escape(old_field)}\b',
                'replacement': rf'\1 {new_field}',
                'field': old_field
            })
            
            # 2. å¯¹è±¡å±æ€§è®¿é—®
            patterns.append({
                'pattern': rf'\.{re.escape(old_field)}\b',
                'replacement': f'.{new_field}',
                'field': old_field
            })
            
            # 3. å¯¹è±¡å±æ€§å®šä¹‰
            patterns.append({
                'pattern': rf'\b{re.escape(old_field)}:',
                'replacement': f'{new_field}:',
                'field': old_field
            })
            
            # 4. è§£æ„èµ‹å€¼
            patterns.append({
                'pattern': rf'\{{[^}}]*\b{re.escape(old_field)}\b[^}}]*\}}',
                'replacement': lambda m, nf=new_field, of=old_field: m.group(0).replace(of, nf),
                'field': old_field
            })
            
            # 5. å‡½æ•°è°ƒç”¨
            patterns.append({
                'pattern': rf'\b{re.escape(old_field)}\s*\(',
                'replacement': f'{new_field}(',
                'field': old_field
            })
            
            # 6. å‡½æ•°å®šä¹‰
            patterns.append({
                'pattern': rf'\bfunction\s+{re.escape(old_field)}\b',
                'replacement': f'function {new_field}',
                'field': old_field
            })
            
            # 7. ç®­å¤´å‡½æ•°èµ‹å€¼
            patterns.append({
                'pattern': rf'\bconst\s+{re.escape(old_field)}\s*=\s*\(',
                'replacement': f'const {new_field} = (',
                'field': old_field
            })
            
            # 8. React Hook ä½¿ç”¨
            patterns.append({
                'pattern': rf'\b{re.escape(old_field)},\s*set',
                'replacement': f'{new_field}, set',
                'field': old_field
            })
            
            # 9. setState å‡½æ•°å
            if old_field.startswith('set'):
                continue  # è·³è¿‡setå¼€å¤´çš„å­—æ®µ
            set_old = f'set{old_field[0].upper()}{old_field[1:]}'
            set_new = f'set_{new_field}'
            patterns.append({
                'pattern': rf'\b{re.escape(set_old)}\b',
                'replacement': set_new,
                'field': old_field
            })
            
        return patterns
        
    def process_file(self, file_path):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            original_content = content
            file_replacements = 0
            
            patterns = self.create_replacement_patterns()
            
            for pattern_info in patterns:
                pattern = pattern_info['pattern']
                replacement = pattern_info['replacement']
                field = pattern_info['field']
                
                if callable(replacement):
                    # å¤„ç†å¤æ‚æ›¿æ¢ï¼ˆå¦‚è§£æ„èµ‹å€¼ï¼‰
                    matches = list(re.finditer(pattern, content))
                    for match in reversed(matches):  # ä»åå¾€å‰æ›¿æ¢é¿å…ä½ç½®åç§»
                        new_text = replacement(match)
                        if new_text != match.group(0):
                            content = content[:match.start()] + new_text + content[match.end():]
                            file_replacements += 1
                            self.stats['field_stats'][field] += 1
                else:
                    # ç®€å•å­—ç¬¦ä¸²æ›¿æ¢
                    new_content, count = re.subn(pattern, replacement, content)
                    if count > 0:
                        content = new_content
                        file_replacements += count
                        self.stats['field_stats'][field] += count
                        
            self.stats['files_processed'] += 1
            
            if content != original_content:
                # å¤‡ä»½åŸæ–‡ä»¶
                self.backup_file(file_path)
                
                # å†™å…¥ä¿®æ”¹åçš„å†…å®¹
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
                self.stats['files_modified'] += 1
                self.stats['total_replacements'] += file_replacements
                
                print(f"âœ… ä¿®æ”¹æ–‡ä»¶: {file_path.relative_to(self.project_root)} (æ›¿æ¢ {file_replacements} å¤„)")
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path} - {str(e)}")
            
    def process_directory(self, directory):
        """å¤„ç†ç›®å½•"""
        dir_path = self.project_root / directory
        if not dir_path.exists():
            print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨: {directory}")
            return
            
        print(f"ğŸ” å¤„ç†ç›®å½•: {directory}")
        
        for file_path in dir_path.rglob('*'):
            if file_path.is_file() and self.should_process_file(file_path):
                self.process_file(file_path)
                
    def generate_report(self):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        end_time = datetime.now()
        duration = end_time - self.stats['start_time']
        
        report = {
            'timestamp': end_time.isoformat(),
            'duration_seconds': duration.total_seconds(),
            'summary': {
                'files_processed': self.stats['files_processed'],
                'files_modified': self.stats['files_modified'],
                'total_replacements': self.stats['total_replacements']
            },
            'field_replacements': {}
        }
        
        # åªåŒ…å«æœ‰æ›¿æ¢çš„å­—æ®µ
        for field, count in self.stats['field_stats'].items():
            if count > 0:
                report['field_replacements'][f'{field} â†’ {FIELD_MAPPINGS[field]}'] = count
                
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.project_root / 'purchase_field_replacement_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        return report
        
    def run(self):
        """æ‰§è¡Œå­—æ®µæ›¿æ¢"""
        print("ğŸš€ å¼€å§‹é‡‡è´­å½•å…¥å­—æ®µè›‡å½¢å‘½åè½¬æ¢...")
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"ğŸ”„ éœ€è¦è½¬æ¢çš„å­—æ®µæ•°é‡: {len(FIELD_MAPPINGS)}")
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        self.create_backup_dir()
        
        # å¤„ç†å„ä¸ªç›®å½•
        for directory in TARGET_DIRECTORIES:
            self.process_directory(directory)
            
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()
        
        # æ‰“å°æ€»ç»“
        print("\n" + "="*60)
        print("ğŸ“Š é‡‡è´­å½•å…¥å­—æ®µè½¬æ¢å®Œæˆï¼")
        print("="*60)
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {report['duration_seconds']:.2f} ç§’")
        print(f"ğŸ“ å¤„ç†æ–‡ä»¶: {report['summary']['files_processed']} ä¸ª")
        print(f"âœï¸  ä¿®æ”¹æ–‡ä»¶: {report['summary']['files_modified']} ä¸ª")
        print(f"ğŸ”„ æ€»æ›¿æ¢æ•°: {report['summary']['total_replacements']} å¤„")
        
        if report['field_replacements']:
            print("\nğŸ¯ å­—æ®µè½¬æ¢è¯¦æƒ…:")
            for field_mapping, count in report['field_replacements'].items():
                print(f"   {field_mapping}: {count} å¤„")
        else:
            print("\nâš ï¸  æœªå‘ç°éœ€è¦è½¬æ¢çš„å­—æ®µ")
            
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: purchase_field_replacement_report.json")
        print(f"ğŸ’¾ å¤‡ä»½ç›®å½•: {BACKUP_DIR}/")
        
def main():
    """ä¸»å‡½æ•°"""
    project_root = Path.cwd()
    replacer = PurchaseFieldReplacer(project_root)
    replacer.run()
    
if __name__ == '__main__':
    main()