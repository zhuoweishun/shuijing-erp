#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ä¿®å¤TypeScripté”™è¯¯è„šæœ¬
ç›®æ ‡ï¼šå°†388ä¸ªé”™è¯¯å‡å°‘åˆ°100ä»¥å†…
é‡ç‚¹å¤„ç†é‡å¤æ€§çš„å­—æ®µå‘½åå’ŒPrismaæ¨¡å‹é”™è¯¯
"""

import os
import re
import shutil
from datetime import datetime
import json

class BatchErrorFixer:
    def __init__(self, backend_dir):
        self.backend_dir = backend_dir
        self.backup_dir = os.path.join(backend_dir, 'backups', f'before_batch_fix_{datetime.now().strftime("%Y%m%d_%H%M%S")}')
        self.changes_log = []
        
    def backup_files(self, files):
        """å¤‡ä»½æ–‡ä»¶"""
        os.makedirs(self.backup_dir, exist_ok=True)
        for file_path in files:
            if os.path.exists(file_path):
                rel_path = os.path.relpath(file_path, self.backend_dir)
                backup_path = os.path.join(self.backup_dir, rel_path)
                os.makedirs(os.path.dirname(backup_path), exist_ok=True)
                shutil.copy2(file_path, backup_path)
                print(f"âœ… å¤‡ä»½æ–‡ä»¶: {rel_path}")
    
    def fix_prisma_model_names(self, content, file_path):
        """ä¿®å¤Prismaæ¨¡å‹åç§°é”™è¯¯"""
        changes = 0
        
        # 1. prisma.material -> prisma.purchase (materialè¡¨ä¸å­˜åœ¨)
        pattern1 = r'prisma\.material\b'
        if re.search(pattern1, content):
            content = re.sub(pattern1, 'prisma.purchase', content)
            changes += len(re.findall(pattern1, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ prisma.material -> prisma.purchase")
        
        # 2. tx.material -> tx.purchase
        pattern2 = r'tx\.material\b'
        if re.search(pattern2, content):
            content = re.sub(pattern2, 'tx.purchase', content)
            changes += len(re.findall(pattern2, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ tx.material -> tx.purchase")
        
        # 3. material_usage -> materialUsage (Prismaç”Ÿæˆçš„æ˜¯é©¼å³°)
        pattern3 = r'prisma\.material_usage\b'
        if re.search(pattern3, content):
            content = re.sub(pattern3, 'prisma.materialUsage', content)
            changes += len(re.findall(pattern3, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ prisma.material_usage -> prisma.materialUsage")
        
        pattern4 = r'tx\.material_usage\b'
        if re.search(pattern4, content):
            content = re.sub(pattern4, 'tx.materialUsage', content)
            changes += len(re.findall(pattern4, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ tx.material_usage -> tx.materialUsage")
        
        return content, changes
    
    def fix_field_names(self, content, file_path):
        """ä¿®å¤å­—æ®µå‘½åé”™è¯¯"""
        changes = 0
        
        # 1. username -> user_name (åœ¨selectä¸­)
        pattern1 = r'username:\s*true'
        if re.search(pattern1, content):
            content = re.sub(pattern1, 'user_name: true', content)
            changes += len(re.findall(pattern1, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ username -> user_name")
        
        # 2. quantity_used_beads -> quantity_used
        pattern2 = r'quantity_used_beads'
        if re.search(pattern2, content):
            content = re.sub(pattern2, 'quantity_used', content)
            changes += len(re.findall(pattern2, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ quantity_used_beads -> quantity_used")
        
        # 3. quantity_used_pieces -> quantity_used
        pattern3 = r'quantity_used_pieces'
        if re.search(pattern3, content):
            content = re.sub(pattern3, 'quantity_used', content)
            changes += len(re.findall(pattern3, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ quantity_used_pieces -> quantity_used")
        
        # 4. createdAt -> created_at (åœ¨å±æ€§è®¿é—®ä¸­)
        pattern4 = r'\.createdAt\b'
        if re.search(pattern4, content):
            content = re.sub(pattern4, '.created_at', content)
            changes += len(re.findall(pattern4, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ .createdAt -> .created_at")
        
        # 5. updatedAt -> updated_at (åœ¨å±æ€§è®¿é—®ä¸­)
        pattern5 = r'\.updatedAt\b'
        if re.search(pattern5, content):
            content = re.sub(pattern5, '.updated_at', content)
            changes += len(re.findall(pattern5, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ .updatedAt -> .updated_at")
        
        # 6. materialUsages -> material_usages (åœ¨includeä¸­)
        pattern6 = r'materialUsages:\s*true'
        if re.search(pattern6, content):
            content = re.sub(pattern6, 'material_usages: true', content)
            changes += len(re.findall(pattern6, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ materialUsages -> material_usages (include)")
        
        pattern7 = r'materialUsages:\s*\{'
        if re.search(pattern7, content):
            content = re.sub(pattern7, 'material_usages: {', content)
            changes += len(re.findall(pattern7, content))
            self.changes_log.append(f"{file_path}: ä¿®å¤ materialUsages -> material_usages (include object)")
        
        # 7. .material_usages (å±æ€§è®¿é—®ï¼Œè¿™ä¸ªåº”è¯¥ä¿æŒè›‡å½¢)
        # è¿™ä¸ªä¸éœ€è¦ä¿®æ”¹ï¼Œå› ä¸ºæ•°æ®åº“å­—æ®µç¡®å®æ˜¯è›‡å½¢çš„
        
        return content, changes
    
    def fix_type_issues(self, content, file_path):
        """ä¿®å¤ç±»å‹ç›¸å…³é—®é¢˜"""
        changes = 0
        
        # 1. æ·»åŠ req.userçš„undefinedæ£€æŸ¥
        pattern1 = r'if \(req\.user\.role'
        if re.search(pattern1, content):
            content = re.sub(pattern1, 'if (req.user?.role', content)
            changes += len(re.findall(pattern1, content))
            self.changes_log.append(f"{file_path}: æ·»åŠ  req.user çš„å¯é€‰é“¾æ“ä½œç¬¦")
        
        # 2. ä¿®å¤nullèµ‹å€¼ç»™Decimalç±»å‹çš„é—®é¢˜
        # è¿™ä¸ªéœ€è¦æ›´å¤æ‚çš„å¤„ç†ï¼Œæš‚æ—¶è·³è¿‡
        
        return content, changes
    
    def remove_unused_imports(self, content, file_path):
        """ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥"""
        changes = 0
        
        # ç§»é™¤æœªä½¿ç”¨çš„zå¯¼å…¥
        if "import { z } from 'zod'" in content and 'z.' not in content:
            content = re.sub(r"import \{ z \} from 'zod'\n?", '', content)
            changes += 1
            self.changes_log.append(f"{file_path}: ç§»é™¤æœªä½¿ç”¨çš„ z å¯¼å…¥")
        
        # ç§»é™¤æœªä½¿ç”¨çš„createSuccessResponseå¯¼å…¥
        if 'createSuccessResponse' in content and 'createSuccessResponse(' not in content:
            content = re.sub(r',\s*createSuccessResponse', '', content)
            changes += 1
            self.changes_log.append(f"{file_path}: ç§»é™¤æœªä½¿ç”¨çš„ createSuccessResponse å¯¼å…¥")
        
        return content, changes
    
    def fix_file(self, file_path):
        """ä¿®å¤å•ä¸ªæ–‡ä»¶"""
        if not os.path.exists(file_path):
            return 0
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        total_changes = 0
        
        # åº”ç”¨å„ç§ä¿®å¤
        content, changes1 = self.fix_prisma_model_names(content, file_path)
        total_changes += changes1
        
        content, changes2 = self.fix_field_names(content, file_path)
        total_changes += changes2
        
        content, changes3 = self.fix_type_issues(content, file_path)
        total_changes += changes3
        
        content, changes4 = self.remove_unused_imports(content, file_path)
        total_changes += changes4
        
        # åªæœ‰åœ¨æœ‰å˜åŒ–æ—¶æ‰å†™å…¥æ–‡ä»¶
        if content != original_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… ä¿®å¤æ–‡ä»¶: {os.path.basename(file_path)} ({total_changes} å¤„ä¿®æ”¹)")
        
        return total_changes
    
    def run(self):
        """è¿è¡Œæ‰¹é‡ä¿®å¤"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡ä¿®å¤TypeScripté”™è¯¯...")
        
        # ç›®æ ‡æ–‡ä»¶åˆ—è¡¨
        target_files = [
            os.path.join(self.backend_dir, 'src', 'routes', 'materials.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'products.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'purchases.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'financial.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'inventory.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'customers.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'skus.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'suppliers.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'users.ts'),
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        existing_files = [f for f in target_files if os.path.exists(f)]
        
        if not existing_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡æ–‡ä»¶")
            return
        
        # å¤‡ä»½æ–‡ä»¶
        print("ğŸ“¦ å¤‡ä»½æ–‡ä»¶...")
        self.backup_files(existing_files)
        
        # ä¿®å¤æ–‡ä»¶
        print("ğŸ”§ å¼€å§‹ä¿®å¤...")
        total_changes = 0
        for file_path in existing_files:
            changes = self.fix_file(file_path)
            total_changes += changes
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_changes': total_changes,
            'files_processed': len(existing_files),
            'backup_location': self.backup_dir,
            'changes_log': self.changes_log
        }
        
        report_path = os.path.join(self.backend_dir, 'batch_fix_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… æ‰¹é‡ä¿®å¤å®Œæˆ!")
        print(f"ğŸ“Š æ€»å…±ä¿®æ”¹: {total_changes} å¤„")
        print(f"ğŸ“ å¤‡ä»½ä½ç½®: {self.backup_dir}")
        print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        print("\nğŸ” å»ºè®®è¿è¡Œ npm run build æ£€æŸ¥å‰©ä½™é”™è¯¯æ•°é‡")

if __name__ == '__main__':
    backend_dir = r'D:\shuijing ERP\backend'
    fixer = BatchErrorFixer(backend_dir)
    fixer.run()