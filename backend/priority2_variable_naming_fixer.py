#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜å…ˆçº§2ä¿®å¤è„šæœ¬ï¼šç»Ÿä¸€å˜é‡å‘½å
ä¿®å¤å˜é‡å®šä¹‰å’Œä½¿ç”¨æ—¶å‘½åä¸ä¸€è‡´çš„é—®é¢˜
ç¡®ä¿å…¨è›‡å½¢å‘½åè§„èŒƒ
"""

import os
import re
import json
import shutil
from datetime import datetime
from pathlib import Path

class Priority2VariableNamingFixer:
    def __init__(self):
        self.backend_dir = Path('.')
        self.src_dir = self.backend_dir / 'src'
        self.backup_dir = Path('../backups/priority2_variable_fixes')
        self.fix_count = 0
        self.processed_files = 0
        self.modified_files = 0
        self.fix_log = []
        
        # å˜é‡å‘½åæ˜ å°„è¡¨ - é©¼å³°åˆ°è›‡å½¢
        self.variable_mappings = {
            # å®¢æˆ·ç›¸å…³å˜é‡
            'customerAddress': 'customer_address',
            'customerName': 'customer_name',
            'customerPhone': 'customer_phone',
            'customerData': 'customer_data',
            'customerInfo': 'customer_info',
            'customerList': 'customer_list',
            'customerLabels': 'customer_labels',
            'customerNotes': 'customer_notes',
            
            # æ—¶é—´ç›¸å…³å˜é‡
            'daysSinceLastPurchase': 'days_since_last_purchase',
            'daysSinceFirstPurchase': 'days_since_first_purchase',
            'lastPurchaseDate': 'last_purchase_date',
            'firstPurchaseDate': 'first_purchase_date',
            'createdAt': 'created_at',
            'updatedAt': 'updated_at',
            
            # ç”¨æˆ·ç›¸å…³å˜é‡
            'userAgent': 'user_agent',
            'userId': 'user_id',
            'userName': 'user_name',
            'userInfo': 'user_info',
            'userData': 'user_data',
            
            # ææ–™ç›¸å…³å˜é‡
            'materialType': 'material_type',
            'materialName': 'material_name',
            'materialData': 'material_data',
            'materialInfo': 'material_info',
            'materialList': 'material_list',
            'materialUsage': 'material_usage',
            
            # SKUç›¸å…³å˜é‡
            'skuData': 'sku_data',
            'skuInfo': 'sku_info',
            'skuList': 'sku_list',
            'skuCode': 'sku_code',
            'skuName': 'sku_name',
            
            # äº§å“ç›¸å…³å˜é‡
            'productData': 'product_data',
            'productInfo': 'product_info',
            'productList': 'product_list',
            'productName': 'product_name',
            'productCode': 'product_code',
            
            # é‡‡è´­ç›¸å…³å˜é‡
            'purchaseData': 'purchase_data',
            'purchaseInfo': 'purchase_info',
            'purchaseList': 'purchase_list',
            'purchaseCode': 'purchase_code',
            'purchaseDate': 'purchase_date',
            
            # è´¢åŠ¡ç›¸å…³å˜é‡
            'totalPrice': 'total_price',
            'unitPrice': 'unit_price',
            'totalValue': 'total_value',
            'totalCost': 'total_cost',
            'materialCost': 'material_cost',
            'laborCost': 'labor_cost',
            
            # åº“å­˜ç›¸å…³å˜é‡
            'inventoryData': 'inventory_data',
            'inventoryInfo': 'inventory_info',
            'inventoryList': 'inventory_list',
            'stockQuantity': 'stock_quantity',
            'availableQuantity': 'available_quantity',
            
            # å…¶ä»–å¸¸è§å˜é‡
            'errorMessage': 'error_message',
            'responseData': 'response_data',
            'requestData': 'request_data',
            'resultData': 'result_data',
            'configData': 'config_data',
            'statusCode': 'status_code',
            'isActive': 'is_active',
            'isValid': 'is_valid',
            'hasError': 'has_error',
            'arrayContains': 'array_contains',
            'stringContains': 'string_contains',
        }
        
        # éœ€è¦ä¿æŠ¤çš„æ ‡å‡†APIå’Œå…³é”®å­—
        self.protected_patterns = [
            r'\bconsole\.',
            r'\bMath\.',
            r'\bObject\.',
            r'\bArray\.',
            r'\bJSON\.',
            r'\bDate\.',
            r'\bString\.',
            r'\bNumber\.',
            r'\bBoolean\.',
            r'\bRegExp\.',
            r'\bPromise\.',
            r'\bsetTimeout\b',
            r'\bsetInterval\b',
            r'\bclearTimeout\b',
            r'\bclearInterval\b',
            r'\brequire\(',
            r'\bimport\s+',
            r'\bexport\s+',
            r'\bfunction\s+',
            r'\bclass\s+',
            r'\binterface\s+',
            r'\btype\s+',
            r'\benum\s+',
        ]
    
    def create_backup(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        if self.backup_dir.exists():
            shutil.rmtree(self.backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºå¤‡ä»½ç›®å½•: {self.backup_dir}")
    
    def backup_file(self, file_path):
        """å¤‡ä»½å•ä¸ªæ–‡ä»¶"""
        relative_path = file_path.relative_to(self.backend_dir)
        backup_path = self.backup_dir / relative_path
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(file_path, backup_path)
    
    def is_protected_context(self, content, start_pos, end_pos):
        """æ£€æŸ¥æ˜¯å¦åœ¨å—ä¿æŠ¤çš„ä¸Šä¸‹æ–‡ä¸­"""
        # è·å–å‘¨å›´çš„ä¸Šä¸‹æ–‡
        context_start = max(0, start_pos - 100)
        context_end = min(len(content), end_pos + 100)
        context = content[context_start:context_end]
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å—ä¿æŠ¤çš„æ¨¡å¼ä¸­
        for pattern in self.protected_patterns:
            if re.search(pattern, context):
                return True
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å­—ç¬¦ä¸²æˆ–æ³¨é‡Šä¸­
        before_context = content[context_start:start_pos]
        
        # æ£€æŸ¥å­—ç¬¦ä¸²ä¸Šä¸‹æ–‡
        single_quotes = before_context.count("'") - before_context.count("\\'")
        double_quotes = before_context.count('"') - before_context.count('\\"')
        template_quotes = before_context.count('`') - before_context.count('\\`')
        
        if (single_quotes % 2 == 1 or double_quotes % 2 == 1 or template_quotes % 2 == 1):
            return True
        
        # æ£€æŸ¥æ³¨é‡Šä¸Šä¸‹æ–‡
        if '//' in before_context.split('\n')[-1]:
            return True
        
        return False
    
    def fix_variable_naming(self, content, file_path):
        """ä¿®å¤å˜é‡å‘½å"""
        original_content = content
        file_fixes = 0
        
        for camel_case, snake_case in self.variable_mappings.items():
            # åŒ¹é…å˜é‡å£°æ˜å’Œä½¿ç”¨çš„æ¨¡å¼
            patterns = [
                # å˜é‡å£°æ˜: const/let/var variableName
                rf'\b(const|let|var)\s+{camel_case}\b',
                # å¯¹è±¡å±æ€§: obj.variableName
                rf'\.{camel_case}\b',
                # å‡½æ•°å‚æ•°: function(variableName)
                rf'\({camel_case}\b',
                rf',\s*{camel_case}\b',
                # èµ‹å€¼: variableName =
                rf'\b{camel_case}\s*=',
                # ä½¿ç”¨: variableName.
                rf'\b{camel_case}\.',
                # è¿”å›: return variableName
                rf'\breturn\s+{camel_case}\b',
                # æ¡ä»¶: if (variableName)
                rf'\bif\s*\(\s*{camel_case}\b',
                # è§£æ„: { variableName }
                rf'\{{\s*{camel_case}\s*\}}',
                rf'\{{[^}}]*,\s*{camel_case}\s*[,}}]',
                # æ•°ç»„è§£æ„: [variableName]
                rf'\[\s*{camel_case}\s*\]',
                rf'\[[^\]]*,\s*{camel_case}\s*[,\]]',
            ]
            
            for pattern in patterns:
                matches = list(re.finditer(pattern, content))
                for match in reversed(matches):  # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
                    start, end = match.span()
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨å—ä¿æŠ¤çš„ä¸Šä¸‹æ–‡ä¸­
                    if self.is_protected_context(content, start, end):
                        continue
                    
                    # æ‰§è¡Œæ›¿æ¢
                    matched_text = match.group()
                    new_text = matched_text.replace(camel_case, snake_case)
                    content = content[:start] + new_text + content[end:]
                    file_fixes += 1
                    
                    self.fix_log.append({
                        'file': str(file_path.relative_to(self.backend_dir)),
                        'line': content[:start].count('\n') + 1,
                        'original': camel_case,
                        'fixed': snake_case,
                        'context': matched_text
                    })
        
        self.fix_count += file_fixes
        return content, file_fixes
    
    def process_file(self, file_path):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            self.processed_files += 1
            fixed_content, file_fixes = self.fix_variable_naming(content, file_path)
            
            if file_fixes > 0:
                # å¤‡ä»½åŸæ–‡ä»¶
                self.backup_file(file_path)
                
                # å†™å…¥ä¿®å¤åçš„å†…å®¹
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(fixed_content)
                
                self.modified_files += 1
                print(f"âœ… ä¿®å¤ {file_path.name}: {file_fixes} å¤„å˜é‡å‘½å")
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def process_directory(self):
        """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰TypeScriptæ–‡ä»¶"""
        ts_files = list(self.src_dir.rglob('*.ts'))
        
        print(f"ğŸ“ æ‰¾åˆ° {len(ts_files)} ä¸ªTypeScriptæ–‡ä»¶")
        
        for file_path in ts_files:
            self.process_file(file_path)
    
    def run_typescript_check(self):
        """è¿è¡ŒTypeScriptç¼–è¯‘æ£€æŸ¥"""
        print("\nğŸ” è¿è¡ŒTypeScriptç¼–è¯‘æ£€æŸ¥...")
        result = os.system('npx tsc --noEmit')
        return result == 0
    
    def generate_report(self):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'processed_files': self.processed_files,
                'modified_files': self.modified_files,
                'total_fixes': self.fix_count,
                'variable_mappings_used': len([m for m in self.variable_mappings.items() if any(log['original'] == m[0] for log in self.fix_log)])
            },
            'fixes_by_file': {},
            'detailed_fixes': self.fix_log
        }
        
        # æŒ‰æ–‡ä»¶ç»Ÿè®¡ä¿®å¤æ•°é‡
        for log in self.fix_log:
            file_name = log['file']
            if file_name not in report['fixes_by_file']:
                report['fixes_by_file'][file_name] = 0
            report['fixes_by_file'][file_name] += 1
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open('priority2_variable_fix_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_report = f"""# ä¼˜å…ˆçº§2ä¿®å¤æŠ¥å‘Šï¼šå˜é‡å‘½åç»Ÿä¸€

## ä¿®å¤æ¦‚è¦

- **å¤„ç†æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **å¤„ç†æ–‡ä»¶æ•°**: {self.processed_files}
- **ä¿®æ”¹æ–‡ä»¶æ•°**: {self.modified_files}
- **æ€»ä¿®å¤æ•°**: {self.fix_count}
- **ä½¿ç”¨çš„å˜é‡æ˜ å°„**: {len([m for m in self.variable_mappings.items() if any(log['original'] == m[0] for log in self.fix_log)])}

## æŒ‰æ–‡ä»¶ç»Ÿè®¡ä¿®å¤æ•°é‡

"""
        
        for file_name, count in sorted(report['fixes_by_file'].items(), key=lambda x: x[1], reverse=True):
            md_report += f"- `{file_name}`: {count}å¤„ä¿®å¤\n"
        
        md_report += f"""

## ä¸»è¦ä¿®å¤ç±»å‹

"""
        
        # ç»Ÿè®¡ä¿®å¤ç±»å‹
        fix_types = {}
        for log in self.fix_log:
            original = log['original']
            if original not in fix_types:
                fix_types[original] = 0
            fix_types[original] += 1
        
        for original, count in sorted(fix_types.items(), key=lambda x: x[1], reverse=True)[:10]:
            snake_case = self.variable_mappings.get(original, 'unknown')
            md_report += f"- `{original}` â†’ `{snake_case}`: {count}å¤„\n"
        
        md_report += f"""

## ä¿®å¤ç­–ç•¥

- âœ… **ç²¾ç¡®åŒ¹é…**: åªä¿®å¤æ˜ç¡®çš„å˜é‡å‘½åä¸ä¸€è‡´é—®é¢˜
- âœ… **ä¸Šä¸‹æ–‡ä¿æŠ¤**: é¿å…ä¿®æ”¹å­—ç¬¦ä¸²ã€æ³¨é‡Šå’Œæ ‡å‡†API
- âœ… **å…¨è›‡å½¢å‘½å**: ç»Ÿä¸€é‡‡ç”¨è›‡å½¢å‘½åè§„èŒƒ
- âœ… **å®‰å…¨å¤‡ä»½**: æ‰€æœ‰ä¿®æ”¹æ–‡ä»¶å·²å¤‡ä»½è‡³ `../backups/priority2_variable_fixes`

## å¤‡ä»½ä¿¡æ¯

- **å¤‡ä»½ç›®å½•**: `../backups/priority2_variable_fixes`
- **å¤‡ä»½æ–‡ä»¶æ•°**: {self.modified_files}
- **å¤‡ä»½æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        with open('priority2_variable_fix_report.md', 'w', encoding='utf-8') as f:
            f.write(md_report)
        
        print(f"\nğŸ“Š ç”Ÿæˆä¿®å¤æŠ¥å‘Š:")
        print(f"   - priority2_variable_fix_report.json")
        print(f"   - priority2_variable_fix_report.md")
    
    def run(self):
        """æ‰§è¡Œä¿®å¤æµç¨‹"""
        print("ğŸš€ å¼€å§‹ä¼˜å…ˆçº§2ä¿®å¤ï¼šå˜é‡å‘½åç»Ÿä¸€")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {self.backend_dir.absolute()}")
        
        # åˆ›å»ºå¤‡ä»½
        self.create_backup()
        
        # å¤„ç†æ–‡ä»¶
        self.process_directory()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        # è¿è¡Œç¼–è¯‘æ£€æŸ¥
        compile_success = self.run_typescript_check()
        
        print(f"\nâœ… ä¼˜å…ˆçº§2ä¿®å¤å®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†æ–‡ä»¶: {self.processed_files}")
        print(f"ğŸ“ ä¿®æ”¹æ–‡ä»¶: {self.modified_files}")
        print(f"ğŸ”§ æ€»ä¿®å¤æ•°: {self.fix_count}")
        print(f"ğŸ’¾ å¤‡ä»½ç›®å½•: {self.backup_dir}")
        print(f"âœ… ç¼–è¯‘æ£€æŸ¥: {'é€šè¿‡' if compile_success else 'å¤±è´¥'}")
        
        return compile_success

if __name__ == '__main__':
    fixer = Priority2VariableNamingFixer()
    fixer.run()