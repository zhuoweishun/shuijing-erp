#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡‡è´­åˆ—è¡¨å­—æ®µè›‡å½¢å‘½åè½¬æ¢è„šæœ¬
æ‰¹é‡å°†é‡‡è´­åˆ—è¡¨ç›¸å…³çš„é©¼å³°å‘½åå­—æ®µè½¬æ¢ä¸ºè›‡å½¢å‘½å
"""

import os
import re
import json
import shutil
import time
from pathlib import Path
from typing import Dict, List, Tuple

# å­—æ®µæ˜ å°„å…³ç³»
FIELD_MAPPINGS = {
    # çŠ¶æ€ç®¡ç†å­—æ®µè½¬æ¢ (23ä¸ª)
    'isLoading': 'is_loading',
    'currentPage': 'current_page',
    'pageSize': 'page_size',
    'totalCount': 'total_count',
    'totalPages': 'total_pages',
    'searchTerm': 'search_term',
    'qualityFilter': 'quality_filter',
    'supplierFilter': 'supplier_filter',
    'materialTypesFilter': 'material_types_filter',
    'specificationMin': 'specification_min',
    'specificationMax': 'specification_max',
    'totalPriceMin': 'total_price_min',
    'totalPriceMax': 'total_price_max',
    'columnFilters': 'column_filters',
    'detailModal': 'detail_modal',
    'isOpen': 'is_open',
    'purchaseId': 'purchase_id',
    'isEditMode': 'is_edit_mode',
    'imagePreview': 'image_preview',
    'imageUrl': 'image_url',
    'altText': 'alt_text',
    'exportExcel': 'export_excel',
    'isVisible': 'is_visible',
    'filterType': 'filter_type',
    
    # å‡½æ•°åè½¬æ¢ (22ä¸ª)
    'fetchPurchases': 'fetch_purchases',
    'fetchAllSuppliers': 'fetch_all_suppliers',
    'applyFiltersImmediately': 'apply_filters_immediately',
    'handleReset': 'handle_reset',
    'handleSort': 'handle_sort',
    'toggleColumnFilter': 'toggle_column_filter',
    'handlePageChange': 'handle_page_change',
    'openDetailModal': 'open_detail_modal',
    'closeDetailModal': 'close_detail_modal',
    'openImagePreview': 'open_image_preview',
    'closeImagePreview': 'close_image_preview',
    'handleExportExcel': 'handle_export_excel',
    'handleEdit': 'handle_edit',
    'formatDate': 'format_date',
    'formatPrice': 'format_price',
    'formatWeight': 'format_weight',
    'formatSensitivePrice': 'format_sensitive_price',
    'formatQuality': 'format_quality',
    'getUniqueSuppliers': 'get_unique_suppliers',
    'getFilterPosition': 'get_filter_position',
    'updateFilterPosition': 'update_filter_position',
    'renderColumnFilter': 'render_column_filter',
    
    # æ ¼å¼åŒ–å‡½æ•°è½¬æ¢ (4ä¸ª)
    'formatProductType': 'format_product_type',
    'formatSpecification': 'format_specification',
    'formatQuantity': 'format_quantity',
    'getFirstPhotoUrl': 'get_first_photo_url'
}

# æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {'.ts', '.tsx', '.js', '.jsx', '.json'}

# éœ€è¦éå†çš„ç›®å½•
TARGET_DIRECTORIES = ['src', 'backend', 'shared', 'tests']

# å¤‡ä»½ç›®å½•
BACKUP_DIR = 'backup_purchase_list_fields'

class PurchaseListFieldReplacer:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backup_dir = self.project_root / BACKUP_DIR
        self.stats = {
            'total_files_processed': 0,
            'files_modified': 0,
            'total_replacements': 0,
            'field_replacements': {field: 0 for field in FIELD_MAPPINGS.keys()},
            'processing_time': 0,
            'modified_files': []
        }
        
    def create_backup_dir(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        if self.backup_dir.exists():
            shutil.rmtree(self.backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºå¤‡ä»½ç›®å½•: {self.backup_dir}")
        
    def backup_file(self, file_path: Path):
        """å¤‡ä»½æ–‡ä»¶"""
        relative_path = file_path.relative_to(self.project_root)
        backup_path = self.backup_dir / relative_path
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(file_path, backup_path)
        
    def should_process_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¯¥æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if file_path.suffix not in SUPPORTED_EXTENSIONS:
            return False
            
        # è·³è¿‡å¤‡ä»½ç›®å½•
        if BACKUP_DIR in str(file_path):
            return False
            
        # è·³è¿‡node_modulesç­‰ç›®å½•
        skip_dirs = {'node_modules', '.git', 'dist', 'build', 'coverage'}
        if any(skip_dir in file_path.parts for skip_dir in skip_dirs):
            return False
            
        return True
        
    def create_replacement_patterns(self) -> List[Tuple[re.Pattern, str, str]]:
        """åˆ›å»ºæ›¿æ¢æ¨¡å¼"""
        patterns = []
        
        for old_field, new_field in FIELD_MAPPINGS.items():
            # ç²¾ç¡®åŒ¹é…æ¨¡å¼ï¼Œé¿å…è¯¯æ›¿æ¢
            # åŒ¹é…å˜é‡å£°æ˜ã€å¯¹è±¡å±æ€§ã€å‡½æ•°è°ƒç”¨ç­‰
            pattern_strings = [
                # å˜é‡å£°æ˜: const/let/var oldField
                rf'\b(const|let|var)\s+{re.escape(old_field)}\b',
                # å¯¹è±¡å±æ€§: .oldField æˆ– ['oldField']
                rf'\.{re.escape(old_field)}\b',
                rf"\['{re.escape(old_field)}'\]",
                rf'\["{re.escape(old_field)}"\]',
                # å‡½æ•°å: function oldField æˆ– oldField = function
                rf'\bfunction\s+{re.escape(old_field)}\b',
                rf'\b{re.escape(old_field)}\s*=\s*function',
                rf'\b{re.escape(old_field)}\s*=\s*\(',
                rf'\b{re.escape(old_field)}\s*:\s*function',
                rf'\b{re.escape(old_field)}\s*:\s*\(',
                # ç®­å¤´å‡½æ•°: oldField = () =>
                rf'\b{re.escape(old_field)}\s*=\s*\([^)]*\)\s*=>',
                rf'\b{re.escape(old_field)}\s*=\s*[^=]*=>',
                # å¯¹è±¡æ–¹æ³•: oldField() æˆ– oldField:
                rf'\b{re.escape(old_field)}\s*\(',
                rf'\b{re.escape(old_field)}\s*:',
                # è§£æ„èµ‹å€¼: { oldField }
                rf'\{{[^}}]*\b{re.escape(old_field)}\b[^}}]*\}}',
                # ç±»å‹å®šä¹‰: oldField?
                rf'\b{re.escape(old_field)}\?',
                # JSXå±æ€§
                rf'\b{re.escape(old_field)}\s*=',
            ]
            
            for pattern_str in pattern_strings:
                try:
                    pattern = re.compile(pattern_str)
                    patterns.append((pattern, old_field, new_field))
                except re.error:
                    continue
                    
        return patterns
        
    def replace_in_content(self, content: str, file_path: Path) -> Tuple[str, int]:
        """åœ¨å†…å®¹ä¸­è¿›è¡Œæ›¿æ¢"""
        modified_content = content
        total_replacements = 0
        
        for old_field, new_field in FIELD_MAPPINGS.items():
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ›¿æ¢ç­–ç•¥
            replacements_made = 0
            
            # 1. æ›¿æ¢å˜é‡å£°æ˜
            pattern = rf'\b(const|let|var)\s+{re.escape(old_field)}\b'
            new_content, count = re.subn(pattern, rf'\1 {new_field}', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 2. æ›¿æ¢å¯¹è±¡å±æ€§è®¿é—®
            pattern = rf'\.{re.escape(old_field)}\b'
            new_content, count = re.subn(pattern, f'.{new_field}', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 3. æ›¿æ¢å¯¹è±¡å±æ€§å®šä¹‰
            pattern = rf'\b{re.escape(old_field)}\s*:'
            new_content, count = re.subn(pattern, f'{new_field}:', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 4. æ›¿æ¢å‡½æ•°è°ƒç”¨
            pattern = rf'\b{re.escape(old_field)}\s*\('
            new_content, count = re.subn(pattern, f'{new_field}(', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 5. æ›¿æ¢å‡½æ•°å®šä¹‰
            pattern = rf'\bfunction\s+{re.escape(old_field)}\b'
            new_content, count = re.subn(pattern, f'function {new_field}', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 6. æ›¿æ¢ç®­å¤´å‡½æ•°
            pattern = rf'\b{re.escape(old_field)}\s*=\s*\('
            new_content, count = re.subn(pattern, f'{new_field} = (', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 7. æ›¿æ¢è§£æ„èµ‹å€¼ä¸­çš„å­—æ®µ
            pattern = rf'(\{{[^}}]*\b){re.escape(old_field)}(\b[^}}]*\}})'
            new_content, count = re.subn(pattern, rf'\1{new_field}\2', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 8. æ›¿æ¢JSXå±æ€§
            pattern = rf'\b{re.escape(old_field)}\s*='
            new_content, count = re.subn(pattern, f'{new_field}=', modified_content)
            modified_content = new_content
            replacements_made += count
            
            # 9. æ›¿æ¢å­—ç¬¦ä¸²ä¸­çš„å±æ€§å
            pattern = rf"'{re.escape(old_field)}'"
            new_content, count = re.subn(pattern, f"'{new_field}'", modified_content)
            modified_content = new_content
            replacements_made += count
            
            pattern = rf'"{re.escape(old_field)}"'
            new_content, count = re.subn(pattern, f'"{new_field}"', modified_content)
            modified_content = new_content
            replacements_made += count
            
            if replacements_made > 0:
                self.stats['field_replacements'][old_field] += replacements_made
                total_replacements += replacements_made
                
        return modified_content, total_replacements
        
    def process_file(self, file_path: Path):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
                
            # è¿›è¡Œæ›¿æ¢
            modified_content, replacements = self.replace_in_content(original_content, file_path)
            
            # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå¤‡ä»½å¹¶å†™å…¥æ–°å†…å®¹
            if replacements > 0:
                self.backup_file(file_path)
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(modified_content)
                    
                self.stats['files_modified'] += 1
                self.stats['total_replacements'] += replacements
                self.stats['modified_files'].append(str(file_path.relative_to(self.project_root)))
                
                print(f"âœ… ä¿®æ”¹æ–‡ä»¶: {file_path.relative_to(self.project_root)} ({replacements}å¤„æ›¿æ¢)")
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path} - {e}")
            
    def process_directory(self, directory: Path):
        """å¤„ç†ç›®å½•"""
        if not directory.exists():
            print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {directory}")
            return
            
        print(f"ğŸ“ å¤„ç†ç›®å½•: {directory}")
        
        for file_path in directory.rglob('*'):
            if file_path.is_file() and self.should_process_file(file_path):
                self.process_file(file_path)
                self.stats['total_files_processed'] += 1
                
    def generate_report(self):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'processing_time_seconds': self.stats['processing_time'],
            'summary': {
                'total_files_processed': self.stats['total_files_processed'],
                'files_modified': self.stats['files_modified'],
                'total_replacements': self.stats['total_replacements']
            },
            'field_replacements': {k: v for k, v in self.stats['field_replacements'].items() if v > 0},
            'modified_files': self.stats['modified_files']
        }
        
        report_file = self.project_root / 'purchase_list_field_replacement_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        print(f"ğŸ“Š ç”ŸæˆæŠ¥å‘Š: {report_file}")
        return report
        
    def run(self):
        """æ‰§è¡Œæ›¿æ¢æ“ä½œ"""
        start_time = time.time()
        
        print("ğŸš€ å¼€å§‹é‡‡è´­åˆ—è¡¨å­—æ®µè›‡å½¢å‘½åè½¬æ¢...")
        print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"ğŸ”„ éœ€è¦è½¬æ¢çš„å­—æ®µæ•°é‡: {len(FIELD_MAPPINGS)}")
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        self.create_backup_dir()
        
        # å¤„ç†å„ä¸ªç›®å½•
        for dir_name in TARGET_DIRECTORIES:
            target_dir = self.project_root / dir_name
            self.process_directory(target_dir)
            
        # è®¡ç®—å¤„ç†æ—¶é—´
        self.stats['processing_time'] = round(time.time() - start_time, 2)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*60)
        print("ğŸ“Š é‡‡è´­åˆ—è¡¨å­—æ®µæ›¿æ¢å®Œæˆç»Ÿè®¡")
        print("="*60)
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {self.stats['processing_time']}ç§’")
        print(f"ğŸ“ å¤„ç†æ–‡ä»¶: {self.stats['total_files_processed']}ä¸ª")
        print(f"âœï¸ ä¿®æ”¹æ–‡ä»¶: {self.stats['files_modified']}ä¸ª")
        print(f"ğŸ”„ æ€»æ›¿æ¢æ•°: {self.stats['total_replacements']}å¤„")
        
        print("\nğŸ¯ æˆåŠŸè½¬æ¢çš„å­—æ®µ:")
        successful_fields = {k: v for k, v in self.stats['field_replacements'].items() if v > 0}
        for i, (field, count) in enumerate(successful_fields.items(), 1):
            snake_case = FIELD_MAPPINGS[field]
            print(f"{i:2d}. {field} â†’ {snake_case} ({count}å¤„)")
            
        if not successful_fields:
            print("   æ— å­—æ®µéœ€è¦è½¬æ¢")
            
        print(f"\nğŸ’¾ å¤‡ä»½ç›®å½•: {self.backup_dir}")
        print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: purchase_list_field_replacement_report.json")
        print("\nğŸ‰ é‡‡è´­åˆ—è¡¨ç›¸å…³çš„è›‡å½¢å‘½åæ”¹é€ å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    project_root = os.getcwd()
    replacer = PurchaseListFieldReplacer(project_root)
    replacer.run()

if __name__ == '__main__':
    main()