#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒé™ã€è§’è‰²ç›¸å…³åŠŸèƒ½å­—æ®µè›‡å½¢å‘½åè½¬æ¢è„šæœ¬
æ‰¹é‡å¤„ç†æƒé™ã€è§’è‰²ç›¸å…³çš„28ä¸ªå­—æ®µçš„è›‡å½¢å‘½åè½¬æ¢
"""

import os
import re
import json
import shutil
from datetime import datetime
from typing import Dict, List, Tuple

# æƒé™ã€è§’è‰²ç›¸å…³å­—æ®µæ˜ å°„è¡¨
FIELD_MAPPINGS = {
    # ç”¨æˆ·è®¤è¯ç›¸å…³
    'username': 'user_name',
    'userId': 'user_id', 
    'userAgent': 'user_agent',
    'loginRequest': 'login_request',
    'loginResponse': 'login_response',
    'lastEditedBy': 'last_edited_by',
    'authToken': 'auth_token',
    
    # æƒé™æ§åˆ¶ç›¸å…³
    'canViewPrice': 'can_view_price',
    'canSell': 'can_sell',
    'canDestroy': 'can_destroy',
    'canAdjust': 'can_adjust',
    'canRefund': 'can_refund',
    'isBoss': 'is_boss',
    'isAuthenticated': 'is_authenticated',
    'isLoading': 'is_loading',
    
    # è®¤è¯çŠ¶æ€ç›¸å…³
    'INSUFFICIENT_PERMISSIONS': 'insufficient_permissions',
    'INVALID_TOKEN': 'invalid_token',
    'TOKEN_EXPIRED': 'token_expired',
    'UNAUTHORIZED': 'unauthorized',
    'redirectOnAuth': 'redirect_on_auth',
    'AUTH_REDIRECT_ERRORS': 'auth_redirect_errors',
    
    # APIè®¤è¯ç›¸å…³
    'authApi': 'auth_api',
    'userApi': 'user_api',
    'updateProfile': 'update_profile',
    'UserManagement': 'user_management',
    'useAuth': 'use_auth',
    'useSkuPermissions': 'use_sku_permissions',
    'useSkuPermission': 'use_sku_permission',
    'checkSkuPermission': 'check_sku_permission',
    'getSkuPermissions': 'get_sku_permissions',
    'requireRole': 'require_role'
}

class PermissionFieldReplacer:
    def __init__(self, base_dir: str):
        self.base_dir = base_dir
        self.backup_dir = os.path.join(base_dir, f"backup_permission_fields_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        self.report = {
            'start_time': datetime.now().isoformat(),
            'total_files_processed': 0,
            'files_modified': 0,
            'total_replacements': 0,
            'field_replacements': {},
            'modified_files': [],
            'errors': []
        }
        
    def create_backup(self, file_path: str) -> str:
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
        try:
            relative_path = os.path.relpath(file_path, self.base_dir)
            backup_path = os.path.join(self.backup_dir, relative_path)
            backup_folder = os.path.dirname(backup_path)
            
            os.makedirs(backup_folder, exist_ok=True)
            shutil.copy2(file_path, backup_path)
            return backup_path
        except Exception as e:
            self.report['errors'].append(f"å¤‡ä»½æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return ""
    
    def should_process_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å¤„ç†è¯¥æ–‡ä»¶"""
        # æ’é™¤å¤‡ä»½ç›®å½•å’Œnode_modules
        if 'backup_' in file_path or 'node_modules' in file_path or '.git' in file_path:
            return False
        
        # åªå¤„ç†.tså’Œ.tsxæ–‡ä»¶
        return file_path.endswith(('.ts', '.tsx'))
    
    def create_replacement_patterns(self) -> List[Tuple[re.Pattern, str, str]]:
        """åˆ›å»ºæ›¿æ¢æ¨¡å¼"""
        patterns = []
        
        for old_field, new_field in FIELD_MAPPINGS.items():
            # 1. å¯¹è±¡å±æ€§è®¿é—®æ¨¡å¼ (obj.field)
            patterns.append((
                re.compile(rf'\b(\w+)\.{re.escape(old_field)}\b'),
                rf'\1.{new_field}',
                f'{old_field} (å±æ€§è®¿é—®)'
            ))
            
            # 2. å¯¹è±¡å±æ€§å®šä¹‰æ¨¡å¼ ({ field: value })
            patterns.append((
                re.compile(rf'\b{re.escape(old_field)}:'),
                f'{new_field}:',
                f'{old_field} (å±æ€§å®šä¹‰)'
            ))
            
            # 3. è§£æ„èµ‹å€¼æ¨¡å¼ ({ field } = obj)
            patterns.append((
                re.compile(rf'\{{\s*{re.escape(old_field)}\s*\}}'),
                f'{{ {new_field} }}',
                f'{old_field} (è§£æ„èµ‹å€¼)'
            ))
            
            # 4. å‡½æ•°å/å˜é‡åæ¨¡å¼
            patterns.append((
                re.compile(rf'\b{re.escape(old_field)}\b(?=\s*[=:(,)]|\s*$)'),
                new_field,
                f'{old_field} (å˜é‡/å‡½æ•°å)'
            ))
            
            # 5. å¯¼å…¥/å¯¼å‡ºæ¨¡å¼
            patterns.append((
                re.compile(rf'(import|export)\s+\{{[^}}]*\b{re.escape(old_field)}\b[^}}]*\}}'),
                lambda m: m.group(0).replace(old_field, new_field),
                f'{old_field} (å¯¼å…¥/å¯¼å‡º)'
            ))
            
            # 6. å­—ç¬¦ä¸²å­—é¢é‡ä¸­çš„å­—æ®µåï¼ˆè°¨æ…å¤„ç†ï¼‰
            patterns.append((
                re.compile(rf"(['\"]){re.escape(old_field)}\1"),
                rf"\1{new_field}\1",
                f'{old_field} (å­—ç¬¦ä¸²å­—é¢é‡)'
            ))
        
        return patterns
    
    def process_file_content(self, content: str, file_path: str) -> Tuple[str, int, Dict[str, int]]:
        """å¤„ç†æ–‡ä»¶å†…å®¹"""
        modified_content = content
        total_replacements = 0
        field_counts = {}
        
        patterns = self.create_replacement_patterns()
        
        for pattern, replacement, field_name in patterns:
            if callable(replacement):
                # å¤„ç†lambdaå‡½æ•°æ›¿æ¢
                matches = list(pattern.finditer(modified_content))
                for match in reversed(matches):  # ä»åå¾€å‰æ›¿æ¢é¿å…ä½ç½®åç§»
                    new_text = replacement(match)
                    modified_content = modified_content[:match.start()] + new_text + modified_content[match.end():]
                    count = 1
            else:
                # å¤„ç†å­—ç¬¦ä¸²æ›¿æ¢
                new_content, count = pattern.subn(replacement, modified_content)
                modified_content = new_content
            
            if count > 0:
                total_replacements += count
                base_field = field_name.split(' ')[0]
                field_counts[base_field] = field_counts.get(base_field, 0) + count
                print(f"  âœ“ {field_name}: {count} æ¬¡æ›¿æ¢")
        
        return modified_content, total_replacements, field_counts
    
    def process_file(self, file_path: str) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            print(f"\nå¤„ç†æ–‡ä»¶: {file_path}")
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            # å¤„ç†å†…å®¹
            modified_content, replacements, field_counts = self.process_file_content(original_content, file_path)
            
            # å¦‚æœæœ‰ä¿®æ”¹ï¼Œåˆ™å¤‡ä»½å¹¶å†™å…¥æ–°å†…å®¹
            if replacements > 0:
                # åˆ›å»ºå¤‡ä»½
                backup_path = self.create_backup(file_path)
                
                # å†™å…¥ä¿®æ”¹åçš„å†…å®¹
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(modified_content)
                
                # æ›´æ–°æŠ¥å‘Š
                self.report['files_modified'] += 1
                self.report['total_replacements'] += replacements
                self.report['modified_files'].append({
                    'file': file_path,
                    'backup': backup_path,
                    'replacements': replacements,
                    'field_counts': field_counts
                })
                
                # æ›´æ–°å­—æ®µæ›¿æ¢ç»Ÿè®¡
                for field, count in field_counts.items():
                    self.report['field_replacements'][field] = self.report['field_replacements'].get(field, 0) + count
                
                print(f"  âœ… æ–‡ä»¶å·²ä¿®æ”¹ï¼Œå…± {replacements} æ¬¡æ›¿æ¢")
                return True
            else:
                print(f"  â­ï¸  æ–‡ä»¶æ— éœ€ä¿®æ”¹")
                return False
                
        except Exception as e:
            error_msg = f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}"
            print(f"  âŒ {error_msg}")
            self.report['errors'].append(error_msg)
            return False
    
    def scan_and_process(self) -> None:
        """æ‰«æå¹¶å¤„ç†æ‰€æœ‰æ–‡ä»¶"""
        print("ğŸš€ å¼€å§‹æƒé™ã€è§’è‰²ç›¸å…³åŠŸèƒ½å­—æ®µè›‡å½¢å‘½åè½¬æ¢...")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {self.base_dir}")
        print(f"ğŸ’¾ å¤‡ä»½ç›®å½•: {self.backup_dir}")
        print(f"ğŸ”„ éœ€è¦è½¬æ¢çš„å­—æ®µæ•°é‡: {len(FIELD_MAPPINGS)}")
        
        # æ‰«æç›®æ ‡ç›®å½•
        target_dirs = ['src', 'backend/src', 'shared']
        
        for target_dir in target_dirs:
            full_dir = os.path.join(self.base_dir, target_dir)
            if not os.path.exists(full_dir):
                print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {full_dir}")
                continue
                
            print(f"\nğŸ“‚ æ‰«æç›®å½•: {full_dir}")
            
            for root, dirs, files in os.walk(full_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    
                    if self.should_process_file(file_path):
                        self.report['total_files_processed'] += 1
                        self.process_file(file_path)
    
    def generate_report(self) -> None:
        """ç”Ÿæˆè½¬æ¢æŠ¥å‘Š"""
        self.report['end_time'] = datetime.now().isoformat()
        self.report['duration'] = str(datetime.fromisoformat(self.report['end_time']) - datetime.fromisoformat(self.report['start_time']))
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = os.path.join(self.base_dir, f"permission_field_conversion_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, ensure_ascii=False, indent=2)
        
        # æ‰“å°æ‘˜è¦æŠ¥å‘Š
        print("\n" + "="*60)
        print("ğŸ“Š æƒé™ã€è§’è‰²ç›¸å…³åŠŸèƒ½å­—æ®µè›‡å½¢å‘½åè½¬æ¢å®ŒæˆæŠ¥å‘Š")
        print("="*60)
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {self.report['duration']}")
        print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ€»æ•°: {self.report['total_files_processed']}")
        print(f"âœï¸  ä¿®æ”¹æ–‡ä»¶æ•°é‡: {self.report['files_modified']}")
        print(f"ğŸ”„ æ€»æ›¿æ¢æ¬¡æ•°: {self.report['total_replacements']}")
        print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        if self.report['field_replacements']:
            print("\nğŸ·ï¸  å­—æ®µæ›¿æ¢ç»Ÿè®¡:")
            sorted_fields = sorted(self.report['field_replacements'].items(), key=lambda x: x[1], reverse=True)
            for field, count in sorted_fields:
                snake_field = FIELD_MAPPINGS.get(field, field)
                print(f"  â€¢ {field} â†’ {snake_field}: {count} æ¬¡")
        
        if self.report['errors']:
            print(f"\nâŒ é”™è¯¯æ•°é‡: {len(self.report['errors'])}")
            for error in self.report['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"  â€¢ {error}")
            if len(self.report['errors']) > 5:
                print(f"  â€¢ ... è¿˜æœ‰ {len(self.report['errors']) - 5} ä¸ªé”™è¯¯")
        
        print("\nâœ… æƒé™ã€è§’è‰²ç›¸å…³åŠŸèƒ½å­—æ®µè›‡å½¢å‘½åè½¬æ¢å®Œæˆï¼")
        print(f"ğŸ’¾ åŸæ–‡ä»¶å·²å¤‡ä»½åˆ°: {self.backup_dir}")

def main():
    """ä¸»å‡½æ•°"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    print("ğŸ”§ æƒé™ã€è§’è‰²ç›¸å…³åŠŸèƒ½å­—æ®µè›‡å½¢å‘½åè½¬æ¢å·¥å…·")
    print(f"ğŸ“ å½“å‰ç›®å½•: {base_dir}")
    
    # ç¡®è®¤æ‰§è¡Œ
    response = input("\nâš ï¸  å³å°†å¼€å§‹æ‰¹é‡è½¬æ¢ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ")
    if response.lower() != 'y':
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return
    
    # æ‰§è¡Œè½¬æ¢
    replacer = PermissionFieldReplacer(base_dir)
    replacer.scan_and_process()
    replacer.generate_report()

if __name__ == "__main__":
    main()