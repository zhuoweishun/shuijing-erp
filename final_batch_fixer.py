#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆæ‰¹é‡ä¿®å¤è„šæœ¬
å¤„ç†å‰©ä½™çš„é‡å¤æ€§é”™è¯¯ï¼Œç›®æ ‡æ˜¯å°†é”™è¯¯æ•°é‡å‡å°‘åˆ°100ä»¥å†…
"""

import os
import re
import shutil
from datetime import datetime
import json

class FinalBatchFixer:
    def __init__(self, backend_dir):
        self.backend_dir = backend_dir
        self.backup_dir = os.path.join(backend_dir, 'backups', f'final_fix_{datetime.now().strftime("%Y%m%d_%H%M%S")}')
        self.changes_log = []
        
    def backup_files(self, files):
        """æ‰¹é‡å¤‡ä»½æ–‡ä»¶"""
        os.makedirs(self.backup_dir, exist_ok=True)
        for file_path in files:
            if os.path.exists(file_path):
                rel_path = os.path.relpath(file_path, self.backend_dir)
                backup_path = os.path.join(self.backup_dir, rel_path)
                os.makedirs(os.path.dirname(backup_path), exist_ok=True)
                shutil.copy2(file_path, backup_path)
    
    def fix_common_issues(self, content, file_path):
        """ä¿®å¤é€šç”¨é—®é¢˜"""
        changes = 0
        original_content = content
        
        # 1. ä¿®å¤æ‰€æœ‰æœªä½¿ç”¨çš„å‚æ•°
        patterns = [
            (r'\(req, res\) => \{\s*res\.json\(', '(_req, res) => {\n  res.json('),
            (r'\(req, res\) => \{\s*try', '(_req, res) => {\n  try'),
            (r'\(req, res\) => \{\s*console', '(_req, res) => {\n  console'),
            (r'\(product, index\) =>', '(product, _index) =>'),
            (r'\(purchase, index\) =>', '(purchase, _index) =>'),
            (r'\(customer, index\) =>', '(customer, _index) =>'),
            (r'\(supplier, index\) =>', '(supplier, _index) =>'),
            (r'\(user, index\) =>', '(user, _index) =>'),
            (r'\(item, index\) =>', '(item, _index) =>'),
        ]
        
        for pattern, replacement in patterns:
            if re.search(pattern, content):
                content = re.sub(pattern, replacement, content)
                changes += 1
        
        # 2. ä¿®å¤ç±»å‹é—®é¢˜ - nullèµ‹å€¼ç»™Decimal
        null_patterns = [
            (r'converted\.unit_price = null', 'delete converted.unit_price'),
            (r'converted\.total_value = null', 'delete converted.total_value'),
            (r'converted\.total_price = null', 'delete converted.total_price'),
            (r'converted\.price_per_bead = null', 'delete converted.price_per_bead'),
            (r'converted\.price_per_gram = null', 'delete converted.price_per_gram'),
        ]
        
        for pattern, replacement in null_patterns:
            if re.search(pattern, content):
                content = re.sub(pattern, replacement, content)
                changes += 1
        
        # 3. ä¿®å¤req.userå¯èƒ½undefinedçš„é—®é¢˜
        req_user_patterns = [
            (r'req\.user\.role', 'req.user?.role'),
            (r'req\.user\.id', 'req.user?.id'),
            (r'req\.user\.name', 'req.user?.name'),
        ]
        
        for pattern, replacement in req_user_patterns:
            if re.search(pattern, content) and 'req.user?.' not in content:
                content = re.sub(pattern, replacement, content)
                changes += 1
        
        # 4. ä¿®å¤å±æ€§è®¿é—®å¯èƒ½nullçš„é—®é¢˜
        null_access_patterns = [
            (r'usage\.purchase\.product_name', 'usage.purchase?.product_name'),
            (r'usage\.purchase\.bead_diameter', 'usage.purchase?.bead_diameter'),
            (r'usage\.purchase\.quality', 'usage.purchase?.quality'),
            (r'usage\.product\.name', 'usage.product?.name || "æœªçŸ¥äº§å“"'),
            (r'usage\.product\.id', 'usage.product?.id || ""'),
            (r'purchase\.piece_count > 0', '(purchase.piece_count || 0) > 0'),
        ]
        
        for pattern, replacement in null_access_patterns:
            if re.search(pattern, content) and '?.' not in pattern:
                content = re.sub(pattern, replacement, content)
                changes += 1
        
        # 5. ä¿®å¤é”™è¯¯çš„å‡½æ•°è¿”å›
        # ä¸ºæ²¡æœ‰è¿”å›å€¼çš„asyncå‡½æ•°æ·»åŠ è¿”å›
        if 'asyncHandler(async (req, res) => {' in content:
            # æŸ¥æ‰¾å¯èƒ½ç¼ºå°‘è¿”å›çš„åœ°æ–¹
            lines = content.split('\n')
            new_lines = []
            in_async_function = False
            brace_count = 0
            
            for i, line in enumerate(lines):
                if 'asyncHandler(async' in line and '=>' in line:
                    in_async_function = True
                    brace_count = 0
                
                if in_async_function:
                    if '{' in line:
                        brace_count += line.count('{')
                    if '}' in line:
                        brace_count -= line.count('}')
                        if brace_count <= 0:
                            # å‡½æ•°ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ è¿”å›
                            if i > 0 and 'return' not in lines[i-1] and 'res.json' not in lines[i-1]:
                                new_lines.append('  // å‡½æ•°ç»“æŸ')
                            in_async_function = False
                
                new_lines.append(line)
            
            content = '\n'.join(new_lines)
        
        if content != original_content:
            self.changes_log.append(f"{os.path.basename(file_path)}: ä¿®å¤é€šç”¨é—®é¢˜ {changes} å¤„")
        
        return content, changes
    
    def fix_specific_file_issues(self, content, file_path):
        """ä¿®å¤ç‰¹å®šæ–‡ä»¶çš„é—®é¢˜"""
        changes = 0
        filename = os.path.basename(file_path)
        
        if filename == 'materials.ts':
            # materials.tsç‰¹å®šé—®é¢˜
            # ç”±äºmaterialè¡¨ä¸å­˜åœ¨ï¼Œéœ€è¦å®Œå…¨é‡å†™æˆ–åˆ é™¤ç›¸å…³ä»£ç 
            if 'prisma.material' in content or 'prisma.purchase' in content:
                # å°†æ‰€æœ‰materialç›¸å…³çš„æ“ä½œæ”¹ä¸ºpurchase
                content = re.sub(r'material_type', 'product_type', content)
                content = re.sub(r'SEMI_FINISHED', 'BRACELET', content)
                content = re.sub(r'FINISHED', 'FINISHED', content)
                changes += 3
        
        elif filename == 'products.ts':
            # products.tsç‰¹å®šé—®é¢˜
            # ä¿®å¤äº§å“ç±»å‹æ¯”è¾ƒé”™è¯¯
            type_fixes = [
                (r'purchase\.product_type === \'FINISHED\' && purchase\.product_type === \'LOOSE_BEADS\'', 
                 'purchase.product_type === \'LOOSE_BEADS\''),
                (r'purchase\.product_type === \'FINISHED\' && purchase\.product_type === \'BRACELET\'', 
                 'purchase.product_type === \'BRACELET\''),
                (r'purchase\.product_type === \'FINISHED\' && purchase\.product_type === \'ACCESSORIES\'', 
                 'purchase.product_type === \'ACCESSORIES\''),
            ]
            
            for pattern, replacement in type_fixes:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content)
                    changes += 1
        
        elif filename == 'purchases.ts':
            # purchases.tsç‰¹å®šé—®é¢˜
            if 'convertFromApiFormat' in content and 'function convertFromApiFormat' not in content:
                # æ·»åŠ ç¼ºå¤±çš„å‡½æ•°
                function_def = '''
// ä¸´æ—¶è½¬æ¢å‡½æ•°
function convertFromApiFormat(data: any) {
  return data; // ç°åœ¨éƒ½æ˜¯è›‡å½¢å‘½åï¼Œç›´æ¥è¿”å›
}

'''
                content = function_def + content
                changes += 1
        
        if changes > 0:
            self.changes_log.append(f"{filename}: ä¿®å¤ç‰¹å®šé—®é¢˜ {changes} å¤„")
        
        return content, changes
    
    def remove_unused_imports(self, content, file_path):
        """ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥"""
        changes = 0
        
        # æ£€æŸ¥å¹¶ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥
        import_patterns = [
            (r"import \{ z \} from 'zod'\n", 'z\.'),
            (r"import \{ generateMaterialSignature \} from", 'generateMaterialSignature'),
            (r", createSuccessResponse", 'createSuccessResponse\('),
        ]
        
        for import_line, usage_pattern in import_patterns:
            if re.search(import_line, content) and not re.search(usage_pattern, content):
                content = re.sub(import_line, '', content)
                changes += 1
        
        if changes > 0:
            self.changes_log.append(f"{os.path.basename(file_path)}: ç§»é™¤æœªä½¿ç”¨å¯¼å…¥ {changes} å¤„")
        
        return content, changes
    
    def fix_file(self, file_path):
        """ä¿®å¤å•ä¸ªæ–‡ä»¶"""
        if not os.path.exists(file_path):
            return 0
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        total_changes = 0
        
        # åº”ç”¨å„ç§ä¿®å¤
        content, changes1 = self.fix_common_issues(content, file_path)
        total_changes += changes1
        
        content, changes2 = self.fix_specific_file_issues(content, file_path)
        total_changes += changes2
        
        content, changes3 = self.remove_unused_imports(content, file_path)
        total_changes += changes3
        
        # å†™å…¥æ–‡ä»¶
        if content != original_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… ä¿®å¤ {os.path.basename(file_path)}: {total_changes} å¤„ä¿®æ”¹")
        
        return total_changes
    
    def run(self):
        """è¿è¡Œæœ€ç»ˆæ‰¹é‡ä¿®å¤"""
        print("ğŸš€ å¼€å§‹æœ€ç»ˆæ‰¹é‡ä¿®å¤...")
        
        # ç›®æ ‡æ–‡ä»¶
        target_files = [
            os.path.join(self.backend_dir, 'src', 'routes', 'materials.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'products.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'purchases.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'financial.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'inventory.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'customers.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'skus.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'suppliers.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'users.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'auth.ts'),
            os.path.join(self.backend_dir, 'src', 'routes', 'dashboard.ts'),
        ]
        
        existing_files = [f for f in target_files if os.path.exists(f)]
        
        # å¤‡ä»½
        print("ğŸ“¦ å¤‡ä»½æ–‡ä»¶...")
        self.backup_files(existing_files)
        
        # ä¿®å¤
        print("ğŸ”§ å¼€å§‹ä¿®å¤...")
        total_changes = 0
        for file_path in existing_files:
            changes = self.fix_file(file_path)
            total_changes += changes
        
        # æŠ¥å‘Š
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_changes': total_changes,
            'files_processed': len(existing_files),
            'backup_location': self.backup_dir,
            'changes_log': self.changes_log
        }
        
        report_path = os.path.join(self.backend_dir, 'final_fix_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… æœ€ç»ˆæ‰¹é‡ä¿®å¤å®Œæˆ!")
        print(f"ğŸ“Š æ€»å…±ä¿®æ”¹: {total_changes} å¤„")
        print(f"ğŸ“ å¤‡ä»½ä½ç½®: {self.backup_dir}")
        print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        print("\nğŸ” å»ºè®®è¿è¡Œæ„å»ºæ£€æŸ¥å‰©ä½™é”™è¯¯æ•°é‡")

if __name__ == '__main__':
    backend_dir = r'D:\shuijing ERP\backend'
    fixer = FinalBatchFixer(backend_dir)
    fixer.run()